"""
RCPSå¯¹æ¯”
"""

import argparse
import logging
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
import math
from utils.meta_augment_2 import (
    MetaAugController, DualTransformWrapper, AugmentationFactory, WeightedWeakAugment,batch_aug_wrapper
)
import random
import shutil
import sys
import time
import numpy as np
import torch
import torch.backends.cudnn as cudnn
import torch.nn.functional as F
import torch.optim as optim
from tensorboardX import SummaryWriter
from torch.utils.data import DataLoader
from torchvision import transforms
from tqdm import tqdm
from dataloaders.la_version1_3 import (
    LAHeart, ToTensor, TwoStreamBatchSampler
)
from networks.vnet_cl3 import VNet
from utils import ramps, losses
from utils.lossesplus import BoundaryLoss, FocalLoss  # éœ€åœ¨æ–‡ä»¶å¤´éƒ¨å¯¼å…¥

class AugmentationController:
    def __init__(self, max_iter):
        self.iter = 0
        self.max_iter = max_iter
        # æ–°å¢åŠ¨æ€å¢å¼ºå‚æ•°
        self.current_strength = 0.1  # åˆå§‹å¢å¼ºå¼ºåº¦

    def get_strength(self):
        """åŠ¨æ€å¢å¼ºå¼ºåº¦"""
        return self.current_strength

    def step(self):
        self.iter = min(self.iter + 1, self.max_iter)
        # çº¿æ€§å¢å¼ºç­–ç•¥
        self.current_strength = 0.1 + 0.4 * (self.iter / self.max_iter)

# ğŸ†• æ–°å¢MPLæŸå¤±æ§åˆ¶å™¨
class MPLController:
    def __init__(self, T=5, alpha=0.9,grad_scale=0.1):
        self.T = T  # å¹³æ»‘çª—å£å¤§å°
        self.alpha = alpha  # æŒ‡æ•°å¹³æ»‘ç³»æ•°
        self.grad_scale = grad_scale
        self.student_loss_history = []
        self.current_trend = 0.0  # å­¦ç”Ÿæ¨¡å‹æ€§èƒ½å˜åŒ–è¶‹åŠ¿

    def compute_meta_grad(self, teacher_loss, student_params):
        """è®¡ç®—å…ƒæ¢¯åº¦ï¼ˆä¿®æ­£å‚æ•°ç­¾åï¼‰"""
        # ç¡®ä¿teacher_losséœ€è¦æ¢¯åº¦
        teacher_loss.requires_grad_(True)

        # è®¡ç®—æ•™å¸ˆå‚æ•°çš„ä¸€é˜¶æ¢¯åº¦
        grad_teacher = torch.autograd.grad(
            teacher_loss,
            student_params,  # è¿™é‡Œåº”ä¸ºæ•™å¸ˆæ¨¡å‹çš„å‚æ•°
            create_graph=True,
            allow_unused=True
        )

        meta_grads = []
        for g_t, s_param in zip(grad_teacher, student_params):
            if g_t is None:
                meta_grads.append(None)
                continue
            # è®¡ç®—äºŒé˜¶å¯¼æ•°
            grad_student = torch.autograd.grad(
                g_t.sum(),
                s_param,
                retain_graph=True,
                allow_unused=True
            )
            meta_grad = -self.grad_scale * (grad_student[0] if grad_student[0] is not None else 0.0)
            meta_grads.append(meta_grad)
        return meta_grads

    def update(self, student_loss):
        """æ›´æ–°å­¦ç”Ÿæ¨¡å‹æŸå¤±è¶‹åŠ¿"""
        self.student_loss_history.append(student_loss)
        if len(self.student_loss_history) > self.T:
            self.student_loss_history.pop(0)

        # è®¡ç®—è¶‹åŠ¿å˜åŒ–
        if len(self.student_loss_history) >= 2:
            delta = self.student_loss_history[-2] - self.student_loss_history[-1]  # æŸå¤±ä¸‹é™ä¸ºæ­£å€¼
            self.current_trend = self.alpha * self.current_trend + (1 - self.alpha) * delta

    def get_teacher_weight(self):
        """ç”Ÿæˆæ•™å¸ˆæ¨¡å‹æŸå¤±æƒé‡"""
        return torch.sigmoid(torch.tensor(self.current_trend))  # è¶‹åŠ¿è¶Šå¥½ï¼Œæƒé‡è¶Šå¤§

parser = argparse.ArgumentParser()
parser.add_argument('--root_path', type=str, default='/home/zlj/workspace/tjy/MeTi-SSL/data/2018LA_Seg_Training Set/', help='Name of Experiment')
parser.add_argument('--exp', type=str, default='train_cl3', help='model_name')
parser.add_argument('--max_iterations', type=int, default=15000, help='maximum epoch number to train')
parser.add_argument('--batch_size', type=int, default=2, help='batch_size per gpu')
parser.add_argument('--labeled_bs', type=int, default=1, help='labeled_batch_size per gpu')
parser.add_argument('--base_lr', type=float, default=0.01, help='maximum epoch number to train')
parser.add_argument('--deterministic', type=int, default=1, help='whether use deterministic training')
parser.add_argument('--seed', type=int, default=1337, help='random seed')
parser.add_argument('--gpu', type=str, default='0', help='GPU to use')
### costs
parser.add_argument('--ema_decay', type=float, default=0.99, help='ema_decay')
parser.add_argument('--consistency_type', type=str, default="mse", help='consistency_type')
parser.add_argument('--consistency', type=float, default=0.1, help='consistency')
parser.add_argument('--consistency_rampup', type=float, default=40.0, help='consistency_rampup')
parser.add_argument('--temperature', type=float, default=0.4, help='ä¼ªæ ‡ç­¾æ¸©åº¦ç¼©æ”¾')
parser.add_argument('--base_threshold', type=float, default=0.7, help='åŸºç¡€ç½®ä¿¡åº¦é˜ˆå€¼')
parser.add_argument('--mc_dropout_rate', type=float, default=0.2, help='MC Dropoutæ¦‚ç‡')
parser.add_argument('--meta_grad_scale', type=float, default=0.1, help='å…ƒæ¢¯åº¦ç¼©æ”¾ç³»æ•°')
parser.add_argument('--grad_clip', type=float, default=3.0, help='æ¢¯åº¦è£å‰ªé˜ˆå€¼')
parser.add_argument('--teacher_alpha', type=float, default=0.99, help='æ•™å¸ˆæ¨¡å‹EMAç³»æ•°')
# æ–°å¢å¯¹æ¯”å­¦ä¹ å‚æ•°
parser.add_argument('--contrast_weight', type=float, default=0.1, help='å¯¹æ¯”å­¦ä¹ æŸå¤±æƒé‡')
parser.add_argument('--contrast_start_iter', type=int, default=2000, help='å¯ç”¨å¯¹æ¯”å­¦ä¹ çš„è¿­ä»£æ¬¡æ•°')
parser.add_argument('--contrast_patch_size', type=int, default=16, help='å¯¹æ¯”å­¦ä¹ è¡¥ä¸å¤§å°')
parser.add_argument('--contrast_temp', type=float, default=0.1, help='å¯¹æ¯”å­¦ä¹ æ¸©åº¦å‚æ•°')
args = parser.parse_args()

train_data_path = args.root_path
snapshot_path = "../model/" + args.exp + "/"

batch_size = args.batch_size * len(args.gpu.split(','))
max_iterations = args.max_iterations
base_lr = args.base_lr
labeled_bs = args.labeled_bs

if args.deterministic:
    cudnn.benchmark = False
    cudnn.deterministic = True
    random.seed(args.seed)
    # np.random.seed(args.seed)
    np.random.seed()
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed(args.seed)

num_classes = 2
patch_size = (112, 112, 80)

def label_smoothing(labels, factor=0.1):
    """æ ‡ç­¾å¹³æ»‘å‡½æ•°"""
    return labels * (1 - factor) + factor / labels.size(1)


def get_current_consistency_weight(epoch):
    return args.consistency * ramps.sigmoid_rampup(epoch, args.consistency_rampup)

def update_ema_variables(model, ema_model, alpha, global_step):
    alpha = min(1 - 1 / (global_step + 1), alpha)
    for ema_param, param in zip(ema_model.parameters(), model.parameters()):
        ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)


if __name__ == "__main__":
    if not os.path.exists(snapshot_path):
        os.makedirs(snapshot_path)
    if os.path.exists(snapshot_path + '/code'):
        shutil.rmtree(snapshot_path + '/code')

    logging.basicConfig(filename=snapshot_path + "/log.txt", level=logging.INFO,
                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')
    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))
    logging.info(str(args))


    # ğŸ†• ä¿®æ”¹æ¨¡å‹åˆ›å»ºéƒ¨åˆ†
    def create_model(ema=False, teacher=False):
        """åˆ›å»ºæ¨¡å‹å¹¶è®¾ç½®æ¢¯åº¦çŠ¶æ€"""
        # ç½‘ç»œç»“æ„å·®å¼‚
        if teacher:  # æ•™å¸ˆæ¨¡å‹åŠ æ·±ç»“æ„
            net = VNet(n_channels=1, n_classes=num_classes, normalization='batchnorm',
                       has_dropout=False,mc_dropout=True, mc_dropout_rate=args.mc_dropout_rate,)
        else:  # å­¦ç”Ÿæ¨¡å‹åŸºç¡€ç»“æ„
            net = VNet(n_channels=1, n_classes=num_classes, normalization='batchnorm', has_dropout=True)
        model = net.cuda()
        # æ¢¯åº¦è®¾ç½®
        if ema:
            for param in model.parameters():
                param.detach_()  # åˆ†ç¦»è®¡ç®—å›¾
                param.requires_grad_(False)  # æ˜¾å¼ç¦ç”¨æ¢¯åº¦
        return model

    # ================= æ¨¡å‹åŠä¼˜åŒ–å™¨åˆå§‹åŒ– =================
    student_model = create_model(teacher=False)  # å¯è®­ç»ƒå­¦ç”Ÿæ¨¡å‹
    teacher_model = create_model(teacher=True)  # å¯è®­ç»ƒæ•™å¸ˆæ¨¡å‹
    teacher_model.load_state_dict(student_model.state_dict(), strict=False)  # å…³é”®ä¿®å¤

    # è®¾ç½®å¯¹æ¯”å­¦ä¹ æ¨¡å—å‚æ•°
    student_model.contrast_learner.patch_size = args.contrast_patch_size
    student_model.contrast_learner.temp = args.contrast_temp
    teacher_model.contrast_learner.patch_size = args.contrast_patch_size
    teacher_model.contrast_learner.temp = args.contrast_temp
    # è®¾ç½®å¯¹æ¯”å­¦ä¹ æ¨¡å—å‚æ•°

    teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=base_lr * 0.1, momentum=0.9, weight_decay=0.0001)
    student_optimizer = optim.SGD(student_model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)

    # ================= MPLæ§åˆ¶å™¨ã€å…ƒæ§åˆ¶å™¨å’Œå¢å¼ºæ§åˆ¶å™¨åˆå§‹åŒ– =================
    mpl_controller = MPLController(T=10, alpha=0.95)  # åˆå§‹åŒ–MPLæ§åˆ¶å™¨
    meta_controller = MetaAugController(num_aug=6,init_temp=0.6,init_weights=[0.166, 0.166, 0.166, 0.166, 0.166, 0.166]).cuda()
    aug_controller = AugmentationController(args.max_iterations)
    # ================= å¢å¼ºç­–ç•¥åŠæ•°æ®åŠ è½½ =================
    labeled_aug_in = transforms.Compose([
        WeightedWeakAugment(AugmentationFactory.get_weak_weighted_augs())
    ])

    # ä¸ºå¯¹æ¯”å­¦ä¹ åˆ›å»ºä¸åŒçš„å¢å¼ºç­–ç•¥
    labeled_aug_weak = transforms.Compose([
        WeightedWeakAugment(AugmentationFactory.get_weak_weighted_augs())
    ])

    labeled_aug_strong = transforms.Compose([
        WeightedWeakAugment(AugmentationFactory.get_strong_weighted_augs())
    ])

    labeled_aug_out = transforms.Compose([
        AugmentationFactory.weak_base_aug(patch_size),
    ])

    unlabeled_aug_in = transforms.Compose([
        WeightedWeakAugment(
            AugmentationFactory.get_strong_weighted_augs(),
            controller=meta_controller
        )
    ])

    unlabeled_aug_out = transforms.Compose([
        AugmentationFactory.strong_base_aug(patch_size),
    ])

    labeled_idxs = list(range(16))
    unlabeled_idxs = list(range(16, 80))

    db_train = LAHeart(
        base_dir=train_data_path,
        split='train',
        transform=transforms.Compose([
            DualTransformWrapper(labeled_aug_out, unlabeled_aug_out),
            ToTensor()
        ]),
        labeled_idxs=labeled_idxs
    )
    batch_sampler = TwoStreamBatchSampler(labeled_idxs, unlabeled_idxs, batch_size, batch_size - labeled_bs)
    def worker_init_fn(worker_id):
        random.seed(args.seed + worker_id)
    trainloader = DataLoader(db_train, batch_sampler=batch_sampler, num_workers=4, pin_memory=True,
                             worker_init_fn=worker_init_fn)

    student_model.train()
    teacher_model.train()

    if args.consistency_type == 'mse':
        consistency_criterion = losses.softmax_mse_loss
    elif args.consistency_type == 'kl':
        consistency_criterion = losses.softmax_kl_loss
    else:
        assert False, args.consistency_type

    writer = SummaryWriter(snapshot_path + '/log')
    logging.info("{} itertations per epoch".format(len(trainloader)))

    iter_num = 0
    max_epoch = max_iterations // len(trainloader) + 1
    lr_ = base_lr
    # å¯¹æ¯”å­¦ä¹ å¯ç”¨æ ‡å¿—
    contrast_enabled = False
    # ================= è®­ç»ƒå¾ªç¯ =================
    for epoch_num in tqdm(range(max_epoch), ncols=70):
        time1 = time.time()
        for i_batch, sampled_batch in enumerate(trainloader):
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¯¹æ¯”å­¦ä¹ 
            if iter_num >= args.contrast_start_iter and not contrast_enabled:
                logging.info(f"å¯ç”¨å¯¹æ¯”å­¦ä¹  at iteration {iter_num}")
                contrast_enabled = True
            # ================= åŠ¨æ€å¢å¼ºæ§åˆ¶ =================
            aug_controller.step()
            current_strength = aug_controller.get_strength()  # è·å–å½“å‰å¢å¼ºå¼ºåº¦
            time2 = time.time()
            # ================= æ•°æ®å‡†å¤‡ =================
            weak_volume_batch = sampled_batch['image'].cuda()
            sampled_batch = batch_aug_wrapper(sampled_batch, labeled_aug_in, unlabeled_aug_in,meta_controller)
            strong_volume_batch = sampled_batch['image'].cuda()
            volume_batch, label_batch = sampled_batch['image'], sampled_batch['label']
            volume_batch, label_batch = volume_batch.cuda(), label_batch.cuda()
            unlabeled_volume_batch = volume_batch[labeled_bs:]

            # ========== é˜¶æ®µ1ï¼šæ•™å¸ˆæ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾ ==========
            with torch.no_grad():
                T = 8  # å¢å¼ºæ¬¡æ•°
                aug_preds = []
                # å™ªå£°æ‰°åŠ¨å¢å¼º
                for _ in range(T // 2):
                    noise = torch.randn_like(unlabeled_volume_batch) * current_strength
                    aug_inputs = unlabeled_volume_batch + noise
                    aug_preds.append(teacher_model(aug_inputs)[0])

                # 3Dæ—‹è½¬å¢å¼ºï¼ˆä¿®æ­£ç‰ˆæœ¬ï¼‰
                for _ in range(T // 2):
                    angle = random.uniform(-10, 10) * current_strength
                    theta = torch.zeros((unlabeled_volume_batch.size(0), 3, 4),
                                        device=unlabeled_volume_batch.device)
                    theta[:, 0, 0] = np.cos(np.radians(angle))
                    theta[:, 0, 1] = -np.sin(np.radians(angle))
                    theta[:, 1, 0] = np.sin(np.radians(angle))
                    theta[:, 1, 1] = np.cos(np.radians(angle))
                    theta[:, 2, 2] = 1.0

                    grid = F.affine_grid(theta, unlabeled_volume_batch.size(), align_corners=False)
                    aug_inputs = F.grid_sample(
                        unlabeled_volume_batch,
                        grid,
                        mode='bilinear',
                        padding_mode='zeros',
                        align_corners=False
                    )
                    aug_preds.append(teacher_model(aug_inputs)[0])

                # é›†æˆé¢„æµ‹ç»“æœ
                teacher_outputs = torch.stack(aug_preds).mean(dim=0)
                teacher_outputs = teacher_outputs / args.temperature  # æ¸©åº¦ç¼©æ”¾

                # åŠ¨æ€ç½®ä¿¡åº¦é˜ˆå€¼
                probs = F.softmax(teacher_outputs, dim=1)
                max_probs, _ = torch.max(probs, dim=1)
                threshold = args.base_threshold + (1 - args.base_threshold) * ramps.sigmoid_rampup(iter_num,max_iterations)
                mask = (max_probs > threshold).float().unsqueeze(1)  # ä¿æŒç»´åº¦å¯¹é½

            # ========== é˜¶æ®µ2ï¼šå­¦ç”Ÿæ¨¡å‹è®­ç»ƒ ==========
            # åŸå§‹è§†å›¾çš„åˆ†å‰²è¾“å‡º
            student_seg_out, student_contrast_feats = student_model(volume_batch, return_contrast_feats=True)

            # å¼±å¢å¼ºè§†å›¾çš„ç‰¹å¾ (ç”¨äºå¯¹æ¯”å­¦ä¹ çš„é”šç‚¹)
            _, weak_contrast_feats = student_model(weak_volume_batch, return_contrast_feats=True)

            # å¼ºå¢å¼ºè§†å›¾çš„ç‰¹å¾ (ç”¨äºå¯¹æ¯”å­¦ä¹ çš„æ­£æ ·æœ¬)
            with torch.no_grad():
                _, strong_contrast_feats = student_model(strong_volume_batch, return_contrast_feats=True)
                strong_contrast_feats = strong_contrast_feats.detach()

            # ç›‘ç£æŸå¤±ï¼ˆå¸¦æ ‡ç­¾å¹³æ»‘ï¼‰
            focal_criterion = FocalLoss(alpha=0.8, gamma=2)# æ–°å¢æŸå¤±å‡½æ•°
            loss_seg = F.cross_entropy(student_seg_out[:labeled_bs],label_batch[:labeled_bs], label_smoothing=0.1)
            outputs_soft = F.softmax(student_seg_out, dim=1)
            loss_seg_dice = losses.dice_loss(outputs_soft[:labeled_bs, 1, :, :, :],label_batch[:labeled_bs] == 1)
            loss_boundary = BoundaryLoss()(outputs_soft[:labeled_bs, 1], (label_batch[:labeled_bs] == 1).float())# æ–°å¢æŸå¤±å‡½æ•°
            loss_focal = focal_criterion(student_seg_out[:labeled_bs], label_batch[:labeled_bs])# æ–°å¢æŸå¤±å‡½æ•°
            supervised_loss = 0.3*(loss_seg + loss_seg_dice) + 0.4*loss_boundary + 0.3*loss_focal

            # ä¸€è‡´æ€§æŸå¤±ï¼ˆå¸¦åŠ¨æ€maskï¼‰
            consistency_weight = get_current_consistency_weight(iter_num // 150)
            consistency_dist = consistency_criterion(
                student_seg_out[labeled_bs:],
                label_smoothing(probs, factor=0.1)  # æ•™å¸ˆæ ‡ç­¾å¹³æ»‘
            )
            # print(f"maskç»´åº¦: {mask.shape}")
            weighted_loss = consistency_dist * mask  # é€æ ·æœ¬åŠ æƒ
            masked_consistency = weighted_loss.view(weighted_loss.shape[0], -1).mean(dim=1)
            consistency_loss = consistency_weight * torch.mean(weighted_loss)
            # ================= æ–°å¢ï¼šå¯¹æ¯”å­¦ä¹ æŸå¤± =================
            _, _, weak_spatial_feats = student_model(weak_volume_batch, return_encoder_feats=True)
            _, _, strong_spatial_feats = student_model(strong_volume_batch, return_encoder_feats=True)

            contrast_loss = 0
            if contrast_enabled:
                for i in range(volume_batch.size(0)):
                    anchor_feat = weak_spatial_feats[i].unsqueeze(0)  # [1, C, D, H, W]
                    positive_feat = strong_spatial_feats[i].unsqueeze(0)  # [1, C, D, H, W]
                    if i < labeled_bs:
                        label_map = label_batch[i].unsqueeze(0).unsqueeze(1)
                        prob_map = None
                    else:
                        pseudo_label = torch.argmax(probs[i - labeled_bs], dim=0).unsqueeze(0).unsqueeze(1)
                        prob_map = max_probs[i - labeled_bs].unsqueeze(0).unsqueeze(1)
                        label_map = pseudo_label

                    # æ–°çš„ RCPS å¯¹æ¯”æŸå¤±
                    contrast_loss += student_model.contrast_learner.rcps_voxel_contrast(
                        anchor_feat,
                        positive_feat,
                        pseudo_labels=label_map,
                        prob_map=prob_map,
                        temperature=args.contrast_temp,
                        topk_neg=32  # å¯é…ç½®
                    )
                contrast_loss = contrast_loss / volume_batch.size(0)
                contrast_weight = args.contrast_weight * min(1.0, (iter_num - args.contrast_start_iter) / 2000)
                weighted_contrast_loss = contrast_weight * contrast_loss
            else:
                weighted_contrast_loss = 0

            # å­¦ç”Ÿåå‘ä¼ æ’­ï¼ˆå¸¦æ¢¯åº¦è£å‰ªï¼‰
            student_loss = supervised_loss + consistency_loss + weighted_contrast_loss
            student_optimizer.zero_grad()

            # ä¿ç•™è®¡ç®—å›¾ä¾›å…ƒå­¦ä¹ 
            with torch.enable_grad():
                student_loss.backward(retain_graph=True)
            meta_controller.update_weights(masked_consistency)  # å…³é”®ä¿®æ”¹ç‚¹
            torch.nn.utils.clip_grad_norm_(student_model.parameters(), args.grad_clip)  # æ–°å¢æ¢¯åº¦è£å‰ª
            student_optimizer.step()

            # ========== é˜¶æ®µ3ï¼šå…ƒå­¦ä¹ æ•™å¸ˆæ›´æ–° ==========
            # ç”Ÿæˆå…ƒä¼ªæ ‡ç­¾ï¼ˆå¸¦åœæ­¢æ¢¯åº¦ï¼‰
            with torch.no_grad():
                meta_labels = torch.softmax(student_seg_out.detach(), dim=1)

            # æ•™å¸ˆå‰å‘
            teacher_outputs = teacher_model(volume_batch, return_contrast_feats=False)

            # æ•™å¸ˆæŸå¤±è®¡ç®—
            teacher_supervised_loss = F.cross_entropy(
                teacher_outputs[:labeled_bs],
                label_batch[:labeled_bs].long(),  # ç¡®ä¿æ ‡ç­¾ä¸ºLongç±»å‹
                label_smoothing=0.1,  # å†…ç½®æ ‡ç­¾å¹³æ»‘
                reduction='mean'
            )
            teacher_consistency_loss = losses.softmax_kl_loss(
                teacher_outputs[labeled_bs:],
                meta_labels[labeled_bs:]
            ).mean()

            # åŠ¨æ€æƒé‡è°ƒæ•´
            teacher_weight = mpl_controller.get_teacher_weight()
            teacher_loss = teacher_supervised_loss + teacher_weight * teacher_consistency_loss

            # æ•™å¸ˆåå‘ä¼ æ’­ï¼ˆå¸¦å…ƒæ¢¯åº¦ï¼‰
            teacher_optimizer.zero_grad()
            teacher_loss.backward(retain_graph=True)

            # åœ¨æ•™å¸ˆåå‘ä¼ æ’­æ—¶ï¼š
            teacher_params = list(teacher_model.parameters())
            student_params = list(student_model.parameters())
            # è®¡ç®—å¹¶åº”ç”¨å…ƒæ¢¯åº¦
            meta_grads = mpl_controller.compute_meta_grad(
                teacher_loss=teacher_consistency_loss,  # ç¡®ä¿æ˜¯æ ‡é‡æŸå¤±
                student_params=list(student_model.parameters())  # ä¼ é€’å­¦ç”Ÿå‚æ•°
            )
            for t_param, meta_g in zip(teacher_model.parameters(), meta_grads):
                if meta_g is not None:
                    t_param.grad += meta_g.to(t_param.device)

            torch.nn.utils.clip_grad_norm_(teacher_model.parameters(), args.grad_clip)  # æ•™å¸ˆæ¢¯åº¦è£å‰ª
            teacher_optimizer.step()

            # ========== é˜¶æ®µ4ï¼šåŒå‘å‚æ•°åŒæ­¥ ==========
            # å­¦ç”Ÿ->æ•™å¸ˆè½¯æ›´æ–°
            alpha_teacher = args.teacher_alpha
            with torch.no_grad():
                for t_param, s_param in zip(teacher_model.parameters(), student_model.parameters()):
                    t_param.data.mul_(alpha_teacher).add_(s_param.data, alpha=1 - alpha_teacher)

            # æ•™å¸ˆ->å­¦ç”ŸEMAåŒæ­¥
            update_ema_variables(teacher_model, student_model, alpha=0.999, global_step=iter_num)

            iter_num = iter_num + 1
            writer.add_scalar('uncertainty/mask_per', torch.sum(mask) / mask.numel(), iter_num)
            writer.add_scalar('uncertainty/threshold', threshold, iter_num)
            writer.add_scalar('lr', lr_, iter_num)
            writer.add_scalar('loss/loss', student_loss, iter_num)
            writer.add_scalar('loss/loss_seg', loss_seg, iter_num)
            writer.add_scalar('loss/loss_seg_dice', loss_seg_dice, iter_num)
            writer.add_scalar('train/consistency_loss', consistency_loss, iter_num)
            writer.add_scalar('train/consistency_weight', consistency_weight, iter_num)
            writer.add_scalar('train/consistency_dist', torch.mean(consistency_dist), iter_num)
            # è®°å½•å¯¹æ¯”å­¦ä¹ æŸå¤±
            if contrast_enabled:
                writer.add_scalar('loss/contrast_loss', contrast_loss, iter_num)
                writer.add_scalar('loss/weighted_contrast_loss', weighted_contrast_loss, iter_num)
            # logging.info('iteration %d : loss : %f cons_dist: %f, loss_weight: %f' %
            #              (iter_num, student_loss.item(), consistency_dist.item(), consistency_weight))
            logging.info('iteration %d : loss : %f  loss_weight: %f' %
                         (iter_num, student_loss.item(),  consistency_weight))

            ## change lr
            def adjust_learning_rate(optimizer, iteration, max_iter, base_lr):
                """ä½™å¼¦é€€ç«è°ƒåº¦"""
                lr = base_lr * (math.cos(math.pi * iteration / max_iter) + 1) / 2
                for param_group in optimizer.param_groups:
                    param_group['lr'] = lr

            if iter_num % 2500 == 0:
                # åŸçº¿æ€§è°ƒæ•´æ”¹ä¸ºï¼š
                adjust_learning_rate(student_optimizer, iter_num, max_iterations, base_lr)
                adjust_learning_rate(teacher_optimizer, iter_num, max_iterations, base_lr * 0.1)
                # åŠ¨æ€è°ƒæ•´å¯¹æ¯”å­¦ä¹ å‚æ•°
                if contrast_enabled:
                    epoch_ratio = iter_num / max_iterations
                    new_threshold = 0.25 + 0.15 * epoch_ratio
                    student_model.contrast_learner.edge_threshold = new_threshold
                    student_model.contrast_learner.loss_weights[0] = 1.0 - 0.3 * epoch_ratio
                    student_model.contrast_learner.loss_weights[1] = 0.7 + 0.3 * epoch_ratio
                    student_model.contrast_learner.topk_neg = int(24 + 8 * epoch_ratio)  # top-KåŠ¨æ€è°ƒæ•´
                    logging.info(
                        f"è°ƒæ•´å¯¹æ¯”å­¦ä¹ å‚æ•°: edge_threshold={new_threshold:.3f}, weights={student_model.contrast_learner.loss_weights}")

            if iter_num % 1000 == 0:
                torch.save({
                    'student': student_model.state_dict(),
                    'teacher': teacher_model.state_dict(),
                    'contrast_learner': student_model.contrast_learner.state_dict(),  # ä¿å­˜å¯¹æ¯”å­¦ä¹ æ¨¡å—
                    'iter_num': iter_num
                }, os.path.join(snapshot_path, f'iter_{iter_num}.pth'))

            if iter_num >= max_iterations:
                break
            time1 = time.time()
        if iter_num >= max_iterations:
            break

    # æœ€ç»ˆä¿å­˜ï¼ˆä¿å­˜æ‰€æœ‰æ¨¡å‹ï¼‰
    torch.save({
        'student': student_model.state_dict(),
        'teacher': teacher_model.state_dict(),
        'contrast_learner': student_model.contrast_learner.state_dict(),
    }, os.path.join(snapshot_path, f'iter_{max_iterations}.pth'))
    writer.close()